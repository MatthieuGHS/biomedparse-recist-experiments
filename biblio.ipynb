{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d358eb1a",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "  body {\n",
    "    font-family: Arial, sans-serif;\n",
    "    margin: 40px;\n",
    "    /* background-color: #ffffff; */\n",
    "    color: #000000;\n",
    "  }\n",
    "  h1 {\n",
    "    text-align: center;\n",
    "    font-size: 24px;\n",
    "    text-decoration: underline;\n",
    "  }\n",
    "  pre {\n",
    "    font-family: \"Courier New\", monospace;\n",
    "    font-size: 14px;\n",
    "    /* background-color: #f9f9f9; */\n",
    "    padding: 12px;\n",
    "    border: 1px solid #ddd;\n",
    "    overflow-x: auto;\n",
    "  }\n",
    "  a {\n",
    "    color: #ffffffff;\n",
    "    text-decoration: none;\n",
    "  }\n",
    "  a:hover {\n",
    "    text-decoration: underline;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<body>\n",
    "  <h1>Biblio / Liens utiles</h1>\n",
    "\n",
    "  <pre>\n",
    "  BiomedParse/\n",
    "    ├── <a href=\"https://arxiv.org/pdf/2405.12971\">BiomedParse: a biomedical foundation model...</a>\n",
    "    ├── <a href=\"https://github.com/microsoft/BiomedParse\">GitHub - microsoft/BiomedParse</a>\n",
    "    └── <a href=\"https://huggingface.co/microsoft/BiomedParse\">Hugging Face - BiomedParse</a>\n",
    "\n",
    "  Explicabilité/\n",
    "    ├── <a href=\"https://arxiv.org/abs/2311.06786\">Review: Explainability of Vision Transformers</a>\n",
    "    ├── <a href=\"https://arxiv.org/pdf/2012.09838\">Transformer Interpretability Beyond Attention</a>\n",
    "    ├── <a href=\"https://arxiv.org/pdf/2005.00928\">Quantifying Attention Flow in Transformers</a>\n",
    "    │   └── <a href=\"https://jacobgil.github.io/deeplearning/vision-transformer-explainability\">Exploring Explainability for ViT</a>\n",
    "    │       ├── <a href=\"https://github.com/jacobgil/vit-explain\">GitHub - vit-explain</a>\n",
    "    │       ├── <a href=\"https://research.google/blog/transformers-for-image-recognition-at-scale/\">Google Research: Transformers at Scale</a>\n",
    "    │       └── <a href=\"https://ai.meta.com/blog/data-efficient-image-transformers-a-promising-new-technique-for-image-classification/\">Meta AI: DeiT</a>\n",
    "    └── Transformers/\n",
    "        ├── <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Visualizing NMT with Attention</a>\n",
    "        │   └── <a href=\"https://www.youtube.com/watch?v=UNmqTiOnRfg\">YouTube: RNNs Introduction (Youtube)</a>\n",
    "        └── <a href=\"https://jalammar.github.io/illustrated-transformer/\">The Illustrated Transformer</a>\n",
    "\n",
    "  Calibration/\n",
    "    ├── <a href=\"https://arxiv.org/abs/2212.12053\">On Calibrating Semantic Segmentation Models</a>\n",
    "    └── <a href=\"https://arxiv.org/abs/2306.16564\">Pareto Optimal Learning for Estimating LLM Errors</a>\n",
    "\n",
    "  Prédiction conforme/\n",
    "    ├── <a href=\"https://arxiv.org/pdf/2107.07511\">A Gentle Introduction to Conformal Prediction</a>\n",
    "    │   ├── <a href=\"https://www.youtube.com/watch?v=nql000Lu_iE&list=PLBa0oe-LYIHa68NOJbMxDTMMjT8Is4WkI\">Explaination videos (Youtube)</a>\n",
    "    │   └── <a href=\"https://github.com/aangelopoulos/conformal-prediction\">Conformal Prediction (Github)</a>\n",
    "    ├── <a href=\"https://arxiv.org/pdf/2503.05618\">Morphological Prediction Sets for Image Segmentation</a>\n",
    "    └── <a href=\"https://arxiv.org/pdf/2405.05145\">Conformal Semantic Image Segmentation</a>\n",
    "        └── <a href=\"https://github.com/deel-ai-papers/conformal-segmentation\">Conformal Segmentation (Github)</a>\n",
    "  Pandas/\n",
    "    └── <a href=\"https://www.youtube.com/watch?v=EhYC02PD_gc\">Pandas Full Python Course - Data Science Fundamentals</a>\n",
    "\n",
    "  MedSAM/\n",
    "    └── <a href=\"https://colab.research.google.com/drive/19WNtRMbpsxeqimBlmJwtd1dzpaIvK2FZ?usp=sharing\">Google collab</a>\n",
    "\n",
    "\n",
    "    \n",
    "  </pre>\n",
    "</body>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
